---
title: Lin.Algebra (Again)
tags:
- review
- learning
- khan
- algebra
desc: After some year without using too much linear algebra, I got a little rusty. Now it is time to revisit it, and maybe learn some new tricks.
layout: post
---
Here I will post some notes on what I reviwed (and learned) during the Khan
Academy course in Linear Algebra.
<!-- more -->
The General Line Formula is able to represent a line in any dimension, instead
of the $$x$$ and $$y$$ usual representation.
\begin{equation}
    L = \\{\,\overrightarrow{u} + \alpha\overrightarrow{v}\;\vert\;\forall\alpha\in\mathbb{R}\\}
\end{equation}
For representing a line in each coordinate, rather than in vector form, you can
use the **parametric equation**. For instance, given 2 3-dimensional vectors: 

$$\begin{equation}
\overrightarrow{v} = 
\begin{bmatrix}
1\\
3\\
4\\
\end{bmatrix}
\,\text{and}\;
\overrightarrow{u} = 
\begin{bmatrix}
5\\
2\\
-1\\
\end{bmatrix}
\end{equation}$$

Then, the parametric equation of the line in a 3-dimensional space defined by
$$\overrightarrow{v}$$ and $$\overrightarrow{u}$$ is:

$$\begin{aligned}
s &: \overrightarrow{v} + \alpha(\overrightarrow{v} - \overrightarrow{u})\\\\
  &: \begin{bmatrix}
        1\\
        3\\
        4\\
    \end{bmatrix} +\alpha
    \begin{bmatrix}
        -4\\
        1\\
        5\\
    \end{bmatrix}\\\\
  &: \begin{cases}
        x = 1 - 4\alpha\\
        y = 3 + \alpha\\
        z = 4 + 5\alpha
     \end{cases}
\end{aligned}$$

### Unit Vectors
Unit vector are vectors whose length (magnitude) is equal to 1. Any vector
$$\overrightarrow{u}$$ can be transformed into a unit vector by dividing the
coordinates by its magnitude:

\begin{equation}
    \hat{u} = \frac{\overrightarrow{u}}{||\,\overrightarrow{u}\,||}
\end{equation}

Also, there are two notable unit vectors, usually denoted by $$\hat{i} =
\begin{bmatrix} 1\\ 0\\ \end{bmatrix}$$ and $$\hat{j} = \begin{bmatrix} 0\\ 1\\
\end{bmatrix}$$.

### Linear Combinations
A linear combination is a summation of scaled vectors $$\alpha_1
\overrightarrow{v}_1 + \alpha_2 \overrightarrow{v}_2 + \ldots + \alpha_n
\overrightarrow{v}_n$$ for every $$\alpha_i \in\mathbb{R}$$. For example, we can write

$$\begin{equation}
    3\begin{bmatrix} 1\\ 0\\ \end{bmatrix} + 
    2\begin{bmatrix} 0\\ 1\\ \end{bmatrix} =
    \begin{bmatrix} 3\\ 2\\ \end{bmatrix}
\end{equation}$$

By combining vectors, it is possible to represent other vectors, creating a set
of vectors called **span**. For instance $$span(\hat{i}, \hat{j}) =
\mathbb{R}^2$$, means that all 2-dimensional vectors can be represented by
combining $$\hat{i}$$ and $$\hat{j}$$.

### Linear Dependency

Linear dependency is a definition related to linear combinations, spans, and
many other linear algebra concepts. We say that two vectors
$$\overrightarrow{u}$$ and $$\overrightarrow{v}$$ are linearly dependent if one
can be written in terms of the other, so

$$\begin{equation}
\left( \begin{bmatrix} 2\\ 4\\ \end{bmatrix}, 
\begin{bmatrix} 4\\ 8\\ \end{bmatrix} \right)
\end{equation}$$

are linearly dependent, because 

$$\begin{equation}
\begin{bmatrix} 4\\ 8\\ \end{bmatrix} =
2\begin{bmatrix} 2\\ 4\\ \end{bmatrix}
\end{equation}$$

In general, a set of vectors $$\overrightarrow{v}_i$$ for $$i = 1,\ldots,n$$ is
linearly dependent if there is a set of scalars $$\alpha_i$$ so that

$$\begin{equation}
\overrightarrow{v}_i = \sum_{j=0;\;j\neq i}^n \alpha_j \overrightarrow{v}_j
\end{equation}$$

and at least one $$\alpha_{j} \neq 0$$. Thus, in the contrary, if this
summation is equal to 0 and all $$\alpha_i$$ is also 0, the set is said to be
**linearly independent**. Therefore, a set of vectors is linearly dependent 

$$\begin{equation}
    \sum_{i=0}^n \alpha_i \overrightarrow{v}_i = \overrightarrow{0}
    \quad\Leftrightarrow\quad \alpha_i = 0\,\forall\,i
\end{equation}$$

Another interpretation of this is that a linearly dependent set is the minimal
set that generates a vector space (span). And adding a vector to a to a set
(dependent or not) won't change the span. This interpretation is actually
close-related to the geometric interpretation.

On the geometric interpretation, a set of linearly independent vectors are
lines that only touch in a single point (the solution to the linear system).
When dependent, they would be parallel (a linear system without solutions), or
touch in more than one point (a linear system with infinite solutions).

Finally, an interesting fact is that any set of vectors whose size is larger
than the vector dimension is a linearly dependent set. Because this creates an
linear system with $$N$$ variables and $$N - 1$$ equations.
